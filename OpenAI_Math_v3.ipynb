{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5JbgTj_HspY"
      },
      "source": [
        "# 0. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q90UxKG3Hspc",
        "outputId": "8d3d779e-a1ea-4561-eb52-ef74e96cb196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.3.0\n",
            "  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4 MB 40 kB/s \n",
            "\u001b[?25hCollecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 45.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.0.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (2.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.37.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.17.3)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 11.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.44.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
            "\u001b[K     |████████████████████████████████| 459 kB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.3.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2.0)\n",
            "Installing collected packages: numpy, tensorflow-estimator, h5py, gast, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.5\n",
            "    Uninstalling numpy-1.21.5:\n",
            "      Successfully uninstalled numpy-1.21.5\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "jaxlib 0.3.2+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.4 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 numpy-1.18.5 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 770 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.17.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.8.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.18.5)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.14.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.37.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.44.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (1.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.2.0)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "!pip install gym\n",
        "!pip install keras\n",
        "!pip install keras-rl2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAdEl_v6Hspe"
      },
      "source": [
        "# 1. Test Random Environment with OpenAI Gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HbJE3puZHspe"
      },
      "outputs": [],
      "source": [
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "import random\n",
        "import sympy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA0ocuFzHspf",
        "outputId": "cd6a2047-99d8-4497-cd81-7a43069736c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 0, 0, 0, 0, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "a = np.array([0,1,2,3,4,5,6,7,8,9])\n",
        "a[(6 - 6%4):(6 - 6%4 + 4)] = [0,0,0,0]\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ASgUobSDHspf",
        "outputId": "e298d585-88c5-4c0a-fa79-877cc07a46aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eq(x + 2*y - 3, 0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FiniteSet((2, 1/2))"
            ],
            "text/latex": "$\\displaystyle \\left\\{\\left( 2, \\  \\frac{1}{2}\\right)\\right\\}$"
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "sample_state = [\n",
        "    [1, 2, -3], # 1x + 2y - 3 = 0   <- first equation\n",
        "    [3, 0, -6]  # 3x - 6 = 0        <- second equation\n",
        "]\n",
        "def state_to_equation(eqNr):\n",
        "    state = sample_state[eqNr]\n",
        "    left = \"{} * x + {} * y + {}\".format(*state)\n",
        "    return left, 0\n",
        "    \n",
        "left1, right1 = state_to_equation(0)\n",
        "eq1 = sympy.Eq(sympy.sympify(left1), right1)\n",
        "print(eq1)\n",
        "               \n",
        "left2, right2 = state_to_equation(1)\n",
        "eq2 = sympy.Eq(sympy.sympify(left2), right2)\n",
        "\n",
        "x,y = sympy.symbols('x y')\n",
        "result = sympy.linsolve([eq1, eq2], (x, y))\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yoqhBc1yHspg"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from functools import reduce\n",
        "from sympy.ntheory import factorint\n",
        "from scipy.stats import norm\n",
        "import re\n",
        "lista = [15, 30, 10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SLkC7g5gHsph"
      },
      "outputs": [],
      "source": [
        "from time import perf_counter as pc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "z2km2lK1NiRi"
      },
      "outputs": [],
      "source": [
        "# Discrete?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "4eDxJS0jHspi"
      },
      "outputs": [],
      "source": [
        "class MathEquationEnv(Env):\n",
        "    \n",
        "    def __init__(self, equation_type: str, number_of_equations: int):\n",
        "        self.number_of_equations = number_of_equations\n",
        "        self.observation_space_number, self.equation = self.state_evaluation(equation_type)\n",
        "        self.observation_space_equation = self.observation_space_number * 1\n",
        "        self.observation_space_number = self.number_of_equations * self.observation_space_number\n",
        "\n",
        "        ## action space is equal to 2 * number of equations * number of variables in the equation\n",
        "        self.action_space = Discrete(2*self.observation_space_number)\n",
        "        ## observation_space is equal to number of equations * number of variables in the equation\n",
        "        self.observation_space = Discrete(self.observation_space_number)\n",
        "        self.state = self.random_state()\n",
        "        \n",
        "        ###R\n",
        "        self.previous_state_value = 0\n",
        "        self.pretty_denominators = [1,2,3,4,5,10,20,25,100]\n",
        "        self.previous_step_denominators = [0,0]\n",
        "        self.previous_step_solvable = 0\n",
        "        ###\n",
        "\n",
        "        # print(\"Initial state:\")\n",
        "        # print(self.state_to_equation(0)[0])\n",
        "        # print(self.state_to_equation(1)[0])\n",
        "        # print()\n",
        "\n",
        "        \n",
        "        self.generator_length = 60\n",
        "        self.variables = sympy.symbols(self.get_symbols(equation_type))\n",
        "        print(self.variables)\n",
        "        x,y = sympy.symbols('x y')\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "    \n",
        "    def get_symbols(self, equation):\n",
        "        return \" \".join(set(re.findall(r\"\\b[a-z]{1}\\b\", equation)))\n",
        "\n",
        "    def state_evaluation(self, equation_type: str) -> (int, str):\n",
        "        pattern = re.compile(r\"[^ +]+\")\n",
        "        strings = pattern.findall(equation_type)\n",
        "        strings.sort()\n",
        "        strings.sort(key=len)\n",
        "        copy_s = [\"\" for x in range(len(strings))]\n",
        "        operations = 0\n",
        "        for i, string in enumerate(strings):\n",
        "            if any(x in string for x in (\"sin\", \"cos\", \"tg\")):\n",
        "                copy_s[i] = string.replace(\"(\", \"(1/2 * pi * {}*\")\n",
        "                copy_s[i] = \"{} * \" + copy_s[i]\n",
        "                operations += 2\n",
        "                continue\n",
        "            copy_s[i] = \"{} * \" + strings[i]\n",
        "                \n",
        "            operations+=1\n",
        "        \n",
        "\n",
        "        print(\" + \".join(copy_s))\n",
        "        return (operations, \" + \".join(copy_s))\n",
        "\n",
        "    def get_all_equations(self):\n",
        "        equations = []\n",
        "        for i in range(self.number_of_equations):\n",
        "          left, right = self.state_to_equation(i)\n",
        "          eq = sympy.Eq(sympy.sympify(left), right)\n",
        "          equations.append(eq)\n",
        "        return equations\n",
        "    \n",
        "    def random_state(self):\n",
        "        random_state = random.choices(range(-10, 10), k=self.observation_space_number)\n",
        "        return random_state\n",
        "    \n",
        "    def state_to_equation(self, eqNr):\n",
        "        eq_state = self.state[self.observation_space_equation * eqNr:self.observation_space_equation * (eqNr+1)]\n",
        "        left = self.equation.format(*eq_state)\n",
        "        #print(left)\n",
        "        return left, 0\n",
        "\n",
        "            \n",
        "    def step(self, action):\n",
        "        \"\"\"A step\n",
        "        \"\"\"\n",
        "\n",
        "        \n",
        "        self.generator_length-=1\n",
        "        info = {}\n",
        "        reward = 0\n",
        "        # if action in (0,2,5,7,10,12,15,17):\n",
        "        #   action = random.choice((1,3,4,6,8,9))\n",
        "        self.state[action%self.observation_space_number] += 1 if action//self.observation_space_number else -1\n",
        "            \n",
        "        ##R\n",
        "        equations = self.get_all_equations()\n",
        "        ##R\n",
        "\n",
        "        # #x,y = sympy.symbols('x y')\n",
        "        # left1, right1 = self.state_to_equation(0)\n",
        "        # eq1 = sympy.Eq(sympy.sympify(left1), right1)\n",
        "                \n",
        "        # left2, right2 = self.state_to_equation(1)\n",
        "        # eq2 = sympy.Eq(sympy.sympify(left2), right2)\n",
        "        \n",
        "        done = False      \n",
        "\n",
        "        ##ending was here\n",
        "        \n",
        "        #print(sympy.sympify(left1), right1)\n",
        "        #print(sympy.sympify(left2), right2)\n",
        "        #print('RESULT', eq1, eq2)\n",
        "        if any(isinstance(equation, bool) for equation in equations):\n",
        "            return self.state, reward, done, info\n",
        "        \n",
        "        # if eq1 == True or eq2 == True or eq1 == False or eq2 == False:\n",
        "        #     return self.state, reward, done, info\n",
        "        \n",
        "        t0 = pc()\n",
        "        try:\n",
        "            t0 = pc()\n",
        "            # result = sympy.nsolve([eq1, eq2], (self.x, self.y), (1,1))\n",
        "            result = sympy.solve(equations, self.variables)\n",
        "            # print(result, type(result))\n",
        "            # print(pc() - t0,\"\\n\", eq1, \"\\n\", eq2, type(eq1))\n",
        "        except Exception:\n",
        "            result = None\n",
        "\n",
        "        ###R\n",
        "\n",
        "        coeffs = [self.state[self.observation_space_equation * x:self.observation_space_equation * (x+1)] for x in range(self.number_of_equations)]\n",
        "        # coeffs1 = self.state[:5]\n",
        "        # coeffs2 = self.state[5:]\n",
        "        \n",
        "        gcds = [reduce(lambda a,b: math.gcd(a,b), coeffs_reduce) for coeffs_reduce in coeffs]\n",
        "        # gcd_equation1 = reduce(lambda a,b,: math.gcd(a,b), coeffs1)\n",
        "        # gcd_equation2 = reduce(lambda a,b,: math.gcd(a,b), coeffs2)\n",
        "        \n",
        "        number_of_divisors = [sum(factorint(gcd).values()) for gcd in gcds]\n",
        "        # numbers_of_divisors1 = sum(factorint(gcd_equation1).values())\n",
        "        # numbers_of_divisors2 = sum(factorint(gcd_equation2).values())\n",
        "        \n",
        "        value1 = sum( [ norm(6, 2).cdf(divisor_number) for divisor_number in number_of_divisors] ) * 10\n",
        "        \n",
        "        reward += ( value1 - self.previous_state_value)\n",
        "\n",
        "        self.previous_state_value = value1\n",
        "\n",
        "\n",
        "        #### NEED expansion and more sofisticated handling of non 1 value results\n",
        "\n",
        "        # try:\n",
        "        #   if result:\n",
        "        #     if result[self.x].q in self.pretty_denominators:\n",
        "        #       if self.previous_step_denominators[0] != 1:\n",
        "        #         reward += 1\n",
        "        #         self.previous_step_denominators[0] = 1\n",
        "        #     else:\n",
        "        #       if self.previous_step_denominators[0] != -1:\n",
        "        #         reward -= 1\n",
        "        #         self.previous_step_denominators[0] = -1\n",
        "\n",
        "        #     if result[self.y].q in self.pretty_denominators:\n",
        "        #       if self.previous_step_denominators[1] != 1: \n",
        "        #         reward += 1\n",
        "        #         self.previous_step_denominators[1] = 1\n",
        "        #     else:\n",
        "        #       if self.previous_step_denominators[1] != -1:\n",
        "        #         reward -= 1\n",
        "        #         self.previous_step_denominators[1] = -1\n",
        "        # except:\n",
        "        #   print(\"Yikes\", result)\n",
        "        \n",
        "        ####\n",
        "         \n",
        "\n",
        "        \n",
        "        # print(value, value - self.previous_state_value)\n",
        "        \n",
        "        # value =+ norm(6, 2).cdf(numbers_of_divisors1)\n",
        "        # value =+ norm(6, 2).cdf(numbers_of_divisors2)\n",
        "        \n",
        "        ## - Harder than I thought (Will have to do some validation beforehand)\n",
        "        # if isinstance(tuple, result):\n",
        "        #   pretty_results = sum( map(lambda x: 1 if x.q in self.pretty_denominators else 0, result) )\n",
        "        # elif isinstance(dict, result):\n",
        "        #   ##implement(easier than the first one)\n",
        "        #   pass\n",
        "\n",
        "        ###\n",
        "\n",
        "        if self.generator_length <= 0:\n",
        "            print(\"Final state:\")\n",
        "            for i in range(self.number_of_equations):\n",
        "              print(self.state_to_equation(i)[0])\n",
        "            print(result)\n",
        "            done = True\n",
        "\n",
        "        #print(result)\n",
        "        if not result:\n",
        "            if self.previous_step_solvable != -1:\n",
        "              reward -= 1\n",
        "              self.previous_step_solvable = -1\n",
        "        else:\n",
        "            if self.previous_step_solvable != 1:\n",
        "              reward += 1\n",
        "              self.previous_step_solvable = 1\n",
        "            # print(\"Final state:\")\n",
        "            # print(self.state_to_equation(0)[0])\n",
        "            # print(self.state_to_equation(1)[0])\n",
        "            # print()\n",
        "            # done = True\n",
        "        \n",
        "        ###R\n",
        "        # self.previous_step_state[ action % 10 ] += 1 if action // 10 else -1\n",
        "        ###\n",
        "            \n",
        "        return self.state, reward, done, info\n",
        "        \n",
        "    def render(self):\n",
        "        # Implement viz\n",
        "        pass\n",
        "    \n",
        "    def reset(self):\n",
        "        self.state = self.random_state()\n",
        "        print(\"Initial state:\")\n",
        "        for i in range(self.number_of_equations):\n",
        "          print(self.state_to_equation(i)[0])\n",
        "        print()\n",
        "        self.generator_length = 60\n",
        "        return self.state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "id": "8fdRXQs8Hspj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c2c44de-ad3f-40ae-dce3-447199b3cf48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{} * 1 + {} * cos(1/2 * pi * {}*x) + {} * sin(1/2 * pi * {}*x)\n",
            "x\n",
            "{} * x + {} * y + {} * z\n",
            "(x, z, y)\n"
          ]
        }
      ],
      "source": [
        "## Do not make additional spaces in the () brackets just the variables like:\n",
        "env = MathEquationEnv(\"sin(x) + cos(x) + 1\", 1)\n",
        "env = MathEquationEnv(\"x + y + z\", 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbcNQ9GgHspj",
        "outputId": "0d0091bb-ea8c-4225-b509-7ecc5ac63606"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 359
        }
      ],
      "source": [
        "env.observation_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Esat66THspl",
        "outputId": "d420ffb4-0ee6-4e4f-e3f1-878f5ffca37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.7763568394002505e-15\n"
          ]
        }
      ],
      "source": [
        "x,y = 0.522022196614492, -0.915915828629164\n",
        "print(8 * x**2 + 5*x -6*y**2 -9*y -8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIWZzB00Hspl",
        "outputId": "d9beeccd-41d3-4373-e91f-c19a00428022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial state:\n",
            "1 * x + -1 * y + -9 * z\n",
            "1 * x + 4 * y + -8 * z\n",
            "-7 * x + -1 * y + -7 * z\n",
            "\n",
            "Final state:\n",
            "-1 * x + 0 * y + -11 * z\n",
            "0 * x + 4 * y + -7 * z\n",
            "-5 * x + 0 * y + -7 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:1 Score:1.0404969409489029\n",
            "Initial state:\n",
            "-5 * x + -7 * y + -4 * z\n",
            "2 * x + -3 * y + -2 * z\n",
            "0 * x + -10 * y + 2 * z\n",
            "\n",
            "Final state:\n",
            "-7 * x + -7 * y + -7 * z\n",
            "2 * x + 0 * y + -2 * z\n",
            "0 * x + -13 * y + 3 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:2 Score:0.09719534588292075\n",
            "Initial state:\n",
            "-4 * x + 2 * y + -7 * z\n",
            "2 * x + 4 * y + 5 * z\n",
            "5 * x + 1 * y + -8 * z\n",
            "\n",
            "Final state:\n",
            "-7 * x + 0 * y + -8 * z\n",
            "5 * x + 6 * y + 9 * z\n",
            "4 * x + 5 * y + -6 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:3 Score:-0.09719534588292078\n",
            "Initial state:\n",
            "-2 * x + 5 * y + 6 * z\n",
            "2 * x + 1 * y + 2 * z\n",
            "2 * x + 1 * y + -5 * z\n",
            "\n",
            "Final state:\n",
            "4 * x + 3 * y + 5 * z\n",
            "-2 * x + 3 * y + 0 * z\n",
            "6 * x + 4 * y + -5 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:4 Score:0.0\n",
            "Initial state:\n",
            "-8 * x + 3 * y + -5 * z\n",
            "8 * x + -7 * y + -10 * z\n",
            "-4 * x + -7 * y + 1 * z\n",
            "\n",
            "Final state:\n",
            "-11 * x + 0 * y + -5 * z\n",
            "8 * x + -9 * y + -10 * z\n",
            "-1 * x + -7 * y + 2 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:5 Score:-2.7755575615628914e-17\n",
            "Initial state:\n",
            "-5 * x + -10 * y + -6 * z\n",
            "-1 * x + -7 * y + 5 * z\n",
            "1 * x + -9 * y + 4 * z\n",
            "\n",
            "Final state:\n",
            "-8 * x + -12 * y + -6 * z\n",
            "2 * x + -6 * y + 5 * z\n",
            "-3 * x + -13 * y + 3 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:6 Score:0.04859767294146039\n",
            "Initial state:\n",
            "-5 * x + 8 * y + 2 * z\n",
            "-9 * x + 9 * y + 6 * z\n",
            "1 * x + 4 * y + 4 * z\n",
            "\n",
            "Final state:\n",
            "-8 * x + 11 * y + 0 * z\n",
            "-9 * x + 4 * y + 7 * z\n",
            "7 * x + 7 * y + 3 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:7 Score:-0.04859767294146039\n",
            "Initial state:\n",
            "-9 * x + -1 * y + 2 * z\n",
            "-7 * x + -8 * y + 5 * z\n",
            "-8 * x + 1 * y + -8 * z\n",
            "\n",
            "Final state:\n",
            "-12 * x + 1 * y + 6 * z\n",
            "-5 * x + -5 * y + 2 * z\n",
            "-6 * x + -5 * y + -11 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:8 Score:2.7755575615628914e-17\n",
            "Initial state:\n",
            "8 * x + -3 * y + -1 * z\n",
            "7 * x + 9 * y + -5 * z\n",
            "-6 * x + -5 * y + -4 * z\n",
            "\n",
            "Final state:\n",
            "5 * x + -2 * y + -3 * z\n",
            "2 * x + 8 * y + -2 * z\n",
            "-2 * x + -5 * y + -9 * z\n",
            "{x: 0, z: 0, y: 0}\n",
            "Episode:9 Score:0.04859767294146039\n",
            "Initial state:\n",
            "-2 * x + -2 * y + 3 * z\n",
            "-3 * x + 7 * y + -8 * z\n",
            "-5 * x + -3 * y + 7 * z\n",
            "\n"
          ]
        }
      ],
      "source": [
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    \n",
        "    while not done:\n",
        "        #env.render()\n",
        "        #print('hmm')\n",
        "        action = env.action_space.sample()\n",
        "        \n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMwyTjVLHspm"
      },
      "source": [
        "# 2. Create a Deep Learning Model with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 331,
      "metadata": {
        "id": "aJhanh8bHspm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-lv9GQhHspm",
        "outputId": "7ab887f7-4c48-4d67-b66f-6e71b2102fa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ],
      "source": [
        "env.observation_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_qs42O_Hspn",
        "outputId": "81a1340a-fe30-4990-bf49-ddaf740730b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "()\n"
          ]
        }
      ],
      "source": [
        "states = env.observation_space.shape\n",
        "print(states)\n",
        "actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 334,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtPJTWoxHspn",
        "outputId": "33ad3a63-d0d6-4b09-cbf8-2bea7697d605"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discrete(40)"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ],
      "source": [
        "env.action_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "2CLeoYH2Hspn"
      },
      "outputs": [],
      "source": [
        "def build_model(observations, actions):\n",
        "    model = Sequential()    \n",
        "    model.add(Dense(observations, activation='relu', input_shape=(1, observations) )  )\n",
        "    model.add(Dense(24, activation='relu'))\n",
        "    model.add(Dense(actions, activation='linear'))\n",
        "    model.add(Flatten())\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "G1HVZv4SHspo"
      },
      "outputs": [],
      "source": [
        "del model "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_building(env):\n",
        "    observation_space = env.observation_space.n\n",
        "    action_space = env.action_space.n\n",
        "    return build_model(observation_space, action_space)"
      ],
      "metadata": {
        "id": "rbFv4c8dbHjg"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "id": "KhE3PNzZHspo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd237a9-edff-4e99-9add-3bd99312b31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{} * 1 + {} * x + {} * y\n",
            "(x, y)\n"
          ]
        }
      ],
      "source": [
        "## Here you create a model with whatever sample equation you want\n",
        "## the variables can only consist of 1 letter so variable x1 or y2 is not permited\n",
        "## + 1 at the end is also important, include it in the equation\n",
        "## if you want a free variable to change\n",
        "env = MathEquationEnv(\"x + y + 1\", 2)\n",
        "model = quick_building(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zgl0xqnHspo",
        "outputId": "6093459e-d3d5-4e4a-9d53-27d653674fc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 1, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ],
      "source": [
        "model.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBlpru5KHspp",
        "outputId": "8dc8acb3-27f5-462f-ec9e-43ce65bc417f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_52 (Dense)             (None, 1, 6)              42        \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 1, 24)             168       \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 1, 12)             300       \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 12)                0         \n",
            "=================================================================\n",
            "Total params: 510\n",
            "Trainable params: 510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6sTY55FHspp"
      },
      "source": [
        "# 3. Build Agent with Keras-RL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "id": "MSt72iprHspp"
      },
      "outputs": [],
      "source": [
        "from rl.agents import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "id": "AtstWe0yHspq"
      },
      "outputs": [],
      "source": [
        "def build_agent(model, actions):\n",
        "    policy = BoltzmannQPolicy()\n",
        "    memory = SequentialMemory(limit=50000, window_length=1)\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
        "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
        "    return dqn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quick_building_agent(model, env):\n",
        "    actions = env.action_space.n\n",
        "    return build_agent(model, actions)"
      ],
      "metadata": {
        "id": "a5kMZcgQdAS_"
      },
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sKlfiXtHspq",
        "outputId": "98f11b6b-effe-4dac-afa4-9f560ae2ce40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 1, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ],
      "source": [
        "tuple(model.input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8IXf-u7Hspq",
        "outputId": "73a9624b-d525-4ded-dcfa-3dcee2da9151"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 5000 steps ...\n",
            "Initial state:\n",
            "0 * 1 + 2 * x + 4 * y\n",
            "6 * 1 + -7 * x + 8 * y\n",
            "\n",
            "Interval 1 (0 steps performed)\n",
            "   11/10000 [..............................] - ETA: 23:11 - reward: 0.1022"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   59/10000 [..............................] - ETA: 24:40 - reward: 0.0182Final state:\n",
            "-4 * 1 + 2 * x + 10 * y\n",
            "-11 * 1 + -22 * x + 8 * y\n",
            "{x: -39/118, y: 55/118}\n",
            "   60/10000 [..............................] - ETA: 24:25 - reward: 0.0179Initial state:\n",
            "-9 * 1 + -8 * x + 6 * y\n",
            "-5 * 1 + -9 * x + -4 * y\n",
            "\n",
            "  119/10000 [..............................] - ETA: 16:38 - reward: 0.0086Final state:\n",
            "-10 * 1 + -9 * x + 8 * y\n",
            "-31 * 1 + -30 * x + -3 * y\n",
            "{x: -278/267, y: 7/89}\n",
            "  120/10000 [..............................] - ETA: 16:35 - reward: 0.0086Initial state:\n",
            "4 * 1 + -6 * x + -1 * y\n",
            "-1 * 1 + -7 * x + -9 * y\n",
            "\n",
            "  179/10000 [..............................] - ETA: 13:47 - reward: 0.0060Final state:\n",
            "6 * 1 + -2 * x + -6 * y\n",
            "-2 * 1 + -5 * x + -3 * y\n",
            "{x: -5/4, y: 17/12}\n",
            "  180/10000 [..............................] - ETA: 13:46 - reward: 0.0060Initial state:\n",
            "-10 * 1 + -5 * x + 7 * y\n",
            "8 * 1 + 5 * x + -7 * y\n",
            "\n",
            "  239/10000 [..............................] - ETA: 12:29 - reward: 0.0045Final state:\n",
            "-5 * 1 + -1 * x + 11 * y\n",
            "18 * 1 + 8 * x + -3 * y\n",
            "{x: -183/85, y: 22/85}\n",
            "Initial state:\n",
            "3 * 1 + -10 * x + -10 * y\n",
            "-4 * 1 + -9 * x + -3 * y\n",
            "\n",
            "  299/10000 [..............................] - ETA: 11:38 - reward: 0.0034Final state:\n",
            "7 * 1 + -14 * x + -11 * y\n",
            "-5 * 1 + -26 * x + 6 * y\n",
            "{x: -13/370, y: 126/185}\n",
            "  300/10000 [..............................] - ETA: 11:38 - reward: 0.0034Initial state:\n",
            "-3 * 1 + -1 * x + -10 * y\n",
            "2 * 1 + -2 * x + 9 * y\n",
            "\n",
            "  358/10000 [>.............................] - ETA: 10:59 - reward: 0.0029Final state:\n",
            "-3 * 1 + -2 * x + -11 * y\n",
            "-1 * 1 + -25 * x + 37 * y\n",
            "{x: -122/349, y: -73/349}\n",
            "  360/10000 [>.............................] - ETA: 10:58 - reward: 0.0029Initial state:\n",
            "2 * 1 + 3 * x + 9 * y\n",
            "-3 * 1 + 6 * x + -7 * y\n",
            "\n",
            "  419/10000 [>.............................] - ETA: 10:36 - reward: 0.0026Final state:\n",
            "14 * 1 + 8 * x + 11 * y\n",
            "-9 * 1 + 4 * x + -2 * y\n",
            "{x: 71/60, y: -32/15}\n",
            "  420/10000 [>.............................] - ETA: 10:36 - reward: 0.0024Initial state:\n",
            "2 * 1 + 6 * x + -8 * y\n",
            "-2 * 1 + 9 * x + 5 * y\n",
            "\n",
            "  479/10000 [>.............................] - ETA: 10:19 - reward: 0.0021Final state:\n",
            "2 * 1 + 1 * x + -7 * y\n",
            "-14 * 1 + 8 * x + 46 * y\n",
            "{x: 1/17, y: 5/17}\n",
            "  480/10000 [>.............................] - ETA: 10:19 - reward: 0.0022Initial state:\n",
            "3 * 1 + -3 * x + 1 * y\n",
            "4 * 1 + -4 * x + -8 * y\n",
            "\n",
            "  539/10000 [>.............................] - ETA: 10:02 - reward: 0.0019Final state:\n",
            "6 * 1 + -1 * x + 3 * y\n",
            "5 * 1 + -5 * x + -11 * y\n",
            "{x: 81/26, y: -25/26}\n",
            "Initial state:\n",
            "6 * 1 + -2 * x + 6 * y\n",
            "-2 * 1 + -1 * x + -3 * y\n",
            "\n",
            "  599/10000 [>.............................] - ETA: 9:43 - reward: 0.0017Final state:\n",
            "5 * 1 + 1 * x + 7 * y\n",
            "2 * 1 + -2 * x + -7 * y\n",
            "{x: 7, y: -12/7}\n",
            "  600/10000 [>.............................] - ETA: 9:43 - reward: 0.0017Initial state:\n",
            "-2 * 1 + 6 * x + -9 * y\n",
            "-7 * 1 + 9 * x + 8 * y\n",
            "\n",
            "  659/10000 [>.............................] - ETA: 9:34 - reward: 0.0016Final state:\n",
            "-10 * 1 + -4 * x + -1 * y\n",
            "-18 * 1 + 7 * x + 23 * y\n",
            "{x: -248/85, y: 142/85}\n",
            "  660/10000 [>.............................] - ETA: 9:33 - reward: 0.0016Initial state:\n",
            "-5 * 1 + -4 * x + -4 * y\n",
            "-4 * 1 + -1 * x + -3 * y\n",
            "\n",
            "  719/10000 [=>............................] - ETA: 9:20 - reward: 0.0014Final state:\n",
            "-4 * 1 + -4 * x + -12 * y\n",
            "0 * 1 + -6 * x + -5 * y\n",
            "{x: 5/13, y: -6/13}\n",
            "  720/10000 [=>............................] - ETA: 9:20 - reward: 0.0017Initial state:\n",
            "-7 * 1 + -2 * x + -1 * y\n",
            "7 * 1 + 9 * x + 2 * y\n",
            "\n",
            "  778/10000 [=>............................] - ETA: 9:10 - reward: 0.0013Final state:\n",
            "-13 * 1 + 0 * x + 0 * y\n",
            "-9 * 1 + 8 * x + 6 * y\n",
            "[]\n",
            "  780/10000 [=>............................] - ETA: 9:09 - reward: 9.6917e-05Initial state:\n",
            "-1 * 1 + -10 * x + 9 * y\n",
            "2 * 1 + -6 * x + -7 * y\n",
            "\n",
            "  838/10000 [=>............................] - ETA: 9:01 - reward: 0.0012Final state:\n",
            "-1 * 1 + -7 * x + 12 * y\n",
            "7 * 1 + -12 * x + -8 * y\n",
            "{x: 19/50, y: 61/200}\n",
            "  840/10000 [=>............................] - ETA: 9:00 - reward: 0.0012Initial state:\n",
            "2 * 1 + 3 * x + 4 * y\n",
            "-3 * 1 + 8 * x + 4 * y\n",
            "\n",
            "  899/10000 [=>............................] - ETA: 8:52 - reward: 0.0012Final state:\n",
            "6 * 1 + 3 * x + 4 * y\n",
            "-1 * 1 + 4 * x + 10 * y\n",
            "{x: -32/7, y: 27/14}\n",
            "  900/10000 [=>............................] - ETA: 8:52 - reward: 0.0011Initial state:\n",
            "-1 * 1 + 2 * x + 0 * y\n",
            "-8 * 1 + -1 * x + 9 * y\n",
            "\n",
            "  959/10000 [=>............................] - ETA: 8:45 - reward: 0.0011Final state:\n",
            "-8 * 1 + 11 * x + 5 * y\n",
            "-10 * 1 + -2 * x + 1 * y\n",
            "{x: -2, y: 6}\n",
            "  960/10000 [=>............................] - ETA: 8:45 - reward: 0.0011Initial state:\n",
            "-8 * 1 + 8 * x + 2 * y\n",
            "3 * 1 + 5 * x + -2 * y\n",
            "\n",
            " 1019/10000 [==>...........................] - ETA: 8:39 - reward: 0.0010Final state:\n",
            "-12 * 1 + 23 * x + 1 * y\n",
            "-9 * 1 + 5 * x + -4 * y\n",
            "{x: 57/97, y: -147/97}\n",
            " 1020/10000 [==>...........................] - ETA: 8:38 - reward: 0.0010Initial state:\n",
            "2 * 1 + -3 * x + 8 * y\n",
            "-3 * 1 + 9 * x + -1 * y\n",
            "\n",
            " 1079/10000 [==>...........................] - ETA: 8:32 - reward: 9.9684e-04Final state:\n",
            "8 * 1 + 3 * x + 17 * y\n",
            "2 * 1 + 10 * x + -6 * y\n",
            "{x: -41/94, y: -37/94}\n",
            " 1080/10000 [==>...........................] - ETA: 8:32 - reward: 9.9592e-04Initial state:\n",
            "-10 * 1 + -6 * x + -10 * y\n",
            "1 * 1 + 8 * x + 8 * y\n",
            "\n",
            " 1139/10000 [==>...........................] - ETA: 8:26 - reward: 9.4433e-04Final state:\n",
            "-10 * 1 + -18 * x + -15 * y\n",
            "1 * 1 + 5 * x + 32 * y\n",
            "{x: -305/501, y: 32/501}\n",
            " 1140/10000 [==>...........................] - ETA: 8:26 - reward: 9.0088e-04Initial state:\n",
            "6 * 1 + 6 * x + -8 * y\n",
            "3 * 1 + -9 * x + -1 * y\n",
            "\n",
            " 1199/10000 [==>...........................] - ETA: 8:21 - reward: 0.0010    Final state:\n",
            "6 * 1 + -12 * x + -6 * y\n",
            "8 * 1 + -9 * x + 24 * y\n",
            "{x: 32/57, y: -7/57}\n",
            " 1200/10000 [==>...........................] - ETA: 8:21 - reward: 0.0010Initial state:\n",
            "8 * 1 + 3 * x + 9 * y\n",
            "-5 * 1 + 4 * x + -2 * y\n",
            "\n",
            " 1242/10000 [==>...........................] - ETA: 8:17 - reward: 8.6602e-04done, took 70.539 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f11097bf9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ],
      "source": [
        "dqn = quick_building_agent(model, env)\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "dqn.fit(env, nb_steps=5000, visualize=False, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3GbxvpYHspq",
        "outputId": "2ed80bda-0c0a-487c-d7df-263fd62c27e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 50 episodes ...\n",
            "Initial state:\n",
            "-8 * x + 7 * y + -9 * 1\n",
            "1 * x + -10 * y + 6 * 1\n",
            "\n",
            "Final state:\n",
            "-8 * x + 7 * y + -69 * 1\n",
            "1 * x + -10 * y + 6 * 1\n",
            "{x: -648/73, y: -21/73}\n",
            "Episode 1: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "1 * x + 9 * y + -3 * 1\n",
            "3 * x + -6 * y + 7 * 1\n",
            "\n",
            "Final state:\n",
            "1 * x + 9 * y + -63 * 1\n",
            "3 * x + -6 * y + 7 * 1\n",
            "{x: 105/11, y: 196/33}\n",
            "Episode 2: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "8 * x + -4 * y + -1 * 1\n",
            "0 * x + -7 * y + 1 * 1\n",
            "\n",
            "Final state:\n",
            "8 * x + -4 * y + -61 * 1\n",
            "0 * x + -7 * y + 1 * 1\n",
            "{x: 431/56, y: 1/7}\n",
            "Episode 3: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "7 * x + -10 * y + 6 * 1\n",
            "9 * x + -7 * y + -6 * 1\n",
            "\n",
            "Final state:\n",
            "-26 * x + -37 * y + 6 * 1\n",
            "9 * x + -7 * y + -6 * 1\n",
            "{x: 264/515, y: -102/515}\n",
            "Episode 4: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "4 * x + -2 * y + 6 * 1\n",
            "-3 * x + -1 * y + 2 * 1\n",
            "\n",
            "Final state:\n",
            "4 * x + -36 * y + 6 * 1\n",
            "-3 * x + -1 * y + 28 * 1\n",
            "{x: 501/56, y: 65/56}\n",
            "Episode 5: reward: 0.049, steps: 60\n",
            "Initial state:\n",
            "-5 * x + 4 * y + -7 * 1\n",
            "5 * x + -2 * y + -10 * 1\n",
            "\n",
            "Final state:\n",
            "-13 * x + -4 * y + -51 * 1\n",
            "5 * x + -2 * y + -10 * 1\n",
            "{x: -31/23, y: -385/46}\n",
            "Episode 6: reward: -0.049, steps: 60\n",
            "Initial state:\n",
            "-5 * x + 8 * y + 0 * 1\n",
            "2 * x + -1 * y + -8 * 1\n",
            "\n",
            "Final state:\n",
            "-10 * x + 8 * y + -46 * 1\n",
            "2 * x + -1 * y + 1 * 1\n",
            "{x: 19/3, y: 41/3}\n",
            "Episode 7: reward: 2.049, steps: 60\n",
            "Initial state:\n",
            "6 * x + -3 * y + -8 * 1\n",
            "4 * x + -6 * y + 2 * 1\n",
            "\n",
            "Final state:\n",
            "6 * x + -3 * y + -68 * 1\n",
            "4 * x + -6 * y + 2 * 1\n",
            "{x: 69/4, y: 71/6}\n",
            "Episode 8: reward: -1.000, steps: 60\n",
            "Initial state:\n",
            "6 * x + -3 * y + -5 * 1\n",
            "-10 * x + 2 * y + 1 * 1\n",
            "\n",
            "Final state:\n",
            "6 * x + -3 * y + -65 * 1\n",
            "-10 * x + 2 * y + 1 * 1\n",
            "{x: -127/18, y: -322/9}\n",
            "Episode 9: reward: -1.049, steps: 60\n",
            "Initial state:\n",
            "-10 * x + -6 * y + -2 * 1\n",
            "2 * x + -3 * y + 6 * 1\n",
            "\n",
            "Final state:\n",
            "-10 * x + -6 * y + -62 * 1\n",
            "2 * x + -3 * y + 6 * 1\n",
            "{x: -37/7, y: -32/21}\n",
            "Episode 10: reward: 0.049, steps: 60\n",
            "Initial state:\n",
            "-7 * x + -5 * y + 1 * 1\n",
            "-1 * x + 4 * y + 3 * 1\n",
            "\n",
            "Final state:\n",
            "-19 * x + -9 * y + 1 * 1\n",
            "-1 * x + 4 * y + -13 * 1\n",
            "{x: -113/85, y: 248/85}\n",
            "Episode 11: reward: -0.049, steps: 60\n",
            "Initial state:\n",
            "9 * x + -9 * y + 8 * 1\n",
            "-3 * x + 6 * y + -1 * 1\n",
            "\n",
            "Final state:\n",
            "9 * x + -39 * y + 8 * 1\n",
            "-3 * x + 6 * y + 29 * 1\n",
            "{x: 131/7, y: 95/21}\n",
            "Episode 12: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "5 * x + -10 * y + 0 * 1\n",
            "-1 * x + 1 * y + 4 * 1\n",
            "\n",
            "Final state:\n",
            "5 * x + -40 * y + 0 * 1\n",
            "-1 * x + 1 * y + 34 * 1\n",
            "{x: 272/7, y: 34/7}\n",
            "Episode 13: reward: 0.049, steps: 60\n",
            "Initial state:\n",
            "2 * x + 6 * y + 7 * 1\n",
            "-1 * x + 5 * y + -10 * 1\n",
            "\n",
            "Final state:\n",
            "2 * x + -2 * y + 7 * 1\n",
            "-1 * x + 22 * y + 25 * 1\n",
            "{x: -34/7, y: -19/14}\n",
            "Episode 14: reward: -0.049, steps: 60\n",
            "Initial state:\n",
            "4 * x + 7 * y + -1 * 1\n",
            "9 * x + 0 * y + -3 * 1\n",
            "\n",
            "Final state:\n",
            "4 * x + 7 * y + -61 * 1\n",
            "9 * x + 0 * y + -3 * 1\n",
            "{x: 1/3, y: 179/21}\n",
            "Episode 15: reward: 1.049, steps: 60\n",
            "Initial state:\n",
            "0 * x + -2 * y + 9 * 1\n",
            "1 * x + 6 * y + -7 * 1\n",
            "\n",
            "Final state:\n",
            "0 * x + -2 * y + 8 * 1\n",
            "1 * x + 25 * y + 33 * 1\n",
            "{x: -133, y: 4}\n",
            "Episode 16: reward: 1.000, steps: 60\n",
            "Initial state:\n",
            "6 * x + -5 * y + -10 * 1\n",
            "-2 * x + 3 * y + -8 * 1\n",
            "\n",
            "Final state:\n",
            "6 * x + -5 * y + -63 * 1\n",
            "-2 * x + 3 * y + -1 * 1\n",
            "{x: 97/4, y: 33/2}\n",
            "Episode 17: reward: -0.049, steps: 60\n",
            "Initial state:\n",
            "3 * x + 8 * y + -4 * 1\n",
            "6 * x + 5 * y + -5 * 1\n",
            "\n",
            "Final state:\n",
            "-13 * x + 8 * y + -39 * 1\n",
            "6 * x + 5 * y + 4 * 1\n",
            "{x: -227/113, y: 182/113}\n",
            "Episode 18: reward: -2.000, steps: 60\n",
            "Initial state:\n",
            "-7 * x + 8 * y + 2 * 1\n",
            "0 * x + 4 * y + -9 * 1\n",
            "\n",
            "Final state:\n",
            "-7 * x + 8 * y + -46 * 1\n",
            "0 * x + 4 * y + 3 * 1\n",
            "{x: -52/7, y: -3/4}\n",
            "Episode 19: reward: 1.000, steps: 60\n",
            "Initial state:\n",
            "0 * x + 3 * y + 8 * 1\n",
            "7 * x + -7 * y + -2 * 1\n",
            "\n",
            "Final state:\n",
            "-11 * x + 3 * y + -41 * 1\n",
            "7 * x + -7 * y + -2 * 1\n",
            "{x: -293/56, y: -309/56}\n",
            "Episode 20: reward: -1.000, steps: 60\n",
            "Initial state:\n",
            "0 * x + 2 * y + -7 * 1\n",
            "6 * x + 9 * y + -9 * 1\n",
            "\n",
            "Final state:\n",
            "-11 * x + 2 * y + -56 * 1\n",
            "6 * x + 9 * y + -9 * 1\n",
            "{x: -162/37, y: 145/37}\n",
            "Episode 21: reward: 0.049, steps: 60\n",
            "Initial state:\n",
            "-1 * x + -9 * y + -2 * 1\n",
            "-8 * x + 9 * y + 4 * 1\n",
            "\n",
            "Final state:\n",
            "-1 * x + -51 * y + -2 * 1\n",
            "-8 * x + 9 * y + 22 * 1\n",
            "{x: 368/139, y: -38/417}\n",
            "Episode 22: reward: -0.049, steps: 60\n",
            "Initial state:\n",
            "4 * x + -9 * y + 0 * 1\n",
            "7 * x + 3 * y + -10 * 1\n",
            "\n",
            "Final state:\n",
            "-8 * x + -9 * y + -48 * 1\n",
            "7 * x + 3 * y + -10 * 1\n",
            "{x: 6, y: -32/3}\n",
            "Episode 23: reward: 2.000, steps: 60\n",
            "Initial state:\n",
            "4 * x + -4 * y + -2 * 1\n",
            "5 * x + -10 * y + 8 * 1\n",
            "\n",
            "Final state:\n",
            "4 * x + -4 * y + -62 * 1\n",
            "5 * x + -10 * y + 8 * 1\n",
            "{x: 163/5, y: 171/10}\n",
            "Episode 24: reward: 0.049, steps: 60\n",
            "Initial state:\n",
            "2 * x + 0 * y + -7 * 1\n",
            "-2 * x + -9 * y + 1 * 1\n",
            "\n",
            "Final state:\n",
            "2 * x + 0 * y + -67 * 1\n",
            "-2 * x + -9 * y + 1 * 1\n",
            "{x: 67/2, y: -22/3}\n",
            "Episode 25: reward: -0.049, steps: 60\n",
            "Initial state:\n",
            "3 * x + 0 * y + 1 * 1\n",
            "-4 * x + 5 * y + -5 * 1\n",
            "\n",
            "Final state:\n",
            "3 * x + -31 * y + 1 * 1\n",
            "-4 * x + 5 * y + 24 * 1\n",
            "{x: 749/109, y: 76/109}\n",
            "Episode 26: reward: -2.000, steps: 60\n",
            "Initial state:\n",
            "7 * x + -8 * y + -3 * 1\n",
            "-5 * x + 8 * y + -4 * 1\n",
            "\n",
            "Final state:\n",
            "7 * x + -8 * y + -15 * 1\n",
            "-5 * x + 26 * y + 26 * 1\n",
            "{x: 91/71, y: -107/142}\n",
            "Episode 27: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "-5 * x + -8 * y + -10 * 1\n",
            "-9 * x + 8 * y + 5 * 1\n",
            "\n",
            "Final state:\n",
            "-57 * x + -8 * y + -10 * 1\n",
            "-10 * x + 1 * y + 5 * 1\n",
            "{x: 30/137, y: -385/137}\n",
            "Episode 28: reward: -0.000, steps: 60\n",
            "Initial state:\n",
            "4 * x + -1 * y + -8 * 1\n",
            "3 * x + 1 * y + -7 * 1\n",
            "\n",
            "Final state:\n",
            "4 * x + -1 * y + -67 * 1\n",
            "3 * x + 1 * y + -6 * 1\n",
            "{x: 73/7, y: -177/7}\n",
            "Episode 29: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "-9 * x + 4 * y + -8 * 1\n",
            "-7 * x + 5 * y + -2 * 1\n",
            "\n",
            "Final state:\n",
            "-67 * x + 4 * y + -8 * 1\n",
            "-7 * x + 3 * y + -2 * 1\n",
            "{x: -16/173, y: 78/173}\n",
            "Episode 30: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "0 * x + -4 * y + 2 * 1\n",
            "-5 * x + -1 * y + -3 * 1\n",
            "\n",
            "Final state:\n",
            "0 * x + -31 * y + 2 * 1\n",
            "-5 * x + -1 * y + 30 * 1\n",
            "{x: 928/155, y: 2/31}\n",
            "Episode 31: reward: -0.000, steps: 60\n",
            "Initial state:\n",
            "-1 * x + 4 * y + -10 * 1\n",
            "5 * x + 1 * y + -6 * 1\n",
            "\n",
            "Final state:\n",
            "-11 * x + 4 * y + -60 * 1\n",
            "5 * x + 1 * y + -6 * 1\n",
            "{x: -36/31, y: 366/31}\n",
            "Episode 32: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "-7 * x + 6 * y + 9 * 1\n",
            "-6 * x + 4 * y + 3 * 1\n",
            "\n",
            "Final state:\n",
            "-33 * x + -28 * y + 9 * 1\n",
            "-6 * x + 4 * y + 3 * 1\n",
            "{x: 2/5, y: -3/20}\n",
            "Episode 33: reward: 2.000, steps: 60\n",
            "Initial state:\n",
            "-8 * x + -2 * y + 5 * 1\n",
            "-1 * x + 9 * y + -5 * 1\n",
            "\n",
            "Final state:\n",
            "-34 * x + -12 * y + 5 * 1\n",
            "-1 * x + 9 * y + -17 * 1\n",
            "{x: -1/2, y: 11/6}\n",
            "Episode 34: reward: -1.000, steps: 60\n",
            "Initial state:\n",
            "-5 * x + -3 * y + -2 * 1\n",
            "5 * x + -8 * y + -10 * 1\n",
            "\n",
            "Final state:\n",
            "-26 * x + -42 * y + -2 * 1\n",
            "5 * x + -8 * y + -10 * 1\n",
            "{x: 202/209, y: -135/209}\n",
            "Episode 35: reward: -0.951, steps: 60\n",
            "Initial state:\n",
            "3 * x + 6 * y + 7 * 1\n",
            "-9 * x + 5 * y + -7 * 1\n",
            "\n",
            "Final state:\n",
            "3 * x + -23 * y + 7 * 1\n",
            "-9 * x + 5 * y + 24 * 1\n",
            "{x: 587/192, y: 45/64}\n",
            "Episode 36: reward: -0.049, steps: 60\n",
            "Initial state:\n",
            "6 * x + 3 * y + 1 * 1\n",
            "-10 * x + -3 * y + -8 * 1\n",
            "\n",
            "Final state:\n",
            "6 * x + 3 * y + -59 * 1\n",
            "-10 * x + -3 * y + -8 * 1\n",
            "{x: -67/4, y: 319/6}\n",
            "Episode 37: reward: 1.000, steps: 60\n",
            "Initial state:\n",
            "4 * x + -7 * y + -4 * 1\n",
            "0 * x + -2 * y + -6 * 1\n",
            "\n",
            "Final state:\n",
            "-5 * x + -8 * y + -54 * 1\n",
            "0 * x + -2 * y + -6 * 1\n",
            "{x: -6, y: -3}\n",
            "Episode 38: reward: 1.049, steps: 60\n",
            "Initial state:\n",
            "0 * x + 4 * y + 8 * 1\n",
            "-4 * x + -5 * y + 2 * 1\n",
            "\n",
            "Final state:\n",
            "0 * x + 4 * y + -52 * 1\n",
            "-4 * x + -5 * y + 2 * 1\n",
            "{x: -63/4, y: 13}\n",
            "Episode 39: reward: 0.165, steps: 60\n",
            "Initial state:\n",
            "1 * x + -8 * y + -4 * 1\n",
            "9 * x + -7 * y + 6 * 1\n",
            "\n",
            "Final state:\n",
            "-20 * x + -47 * y + -4 * 1\n",
            "9 * x + -7 * y + 6 * 1\n",
            "{x: -310/563, y: 84/563}\n",
            "Episode 40: reward: -2.214, steps: 60\n",
            "Initial state:\n",
            "0 * x + -7 * y + -6 * 1\n",
            "6 * x + 1 * y + -2 * 1\n",
            "\n",
            "Final state:\n",
            "-2 * x + -7 * y + -64 * 1\n",
            "6 * x + 1 * y + -2 * 1\n",
            "{x: 39/20, y: -97/10}\n",
            "Episode 41: reward: 2.000, steps: 60\n",
            "Initial state:\n",
            "5 * x + 9 * y + 8 * 1\n",
            "1 * x + -7 * y + 3 * 1\n",
            "\n",
            "Final state:\n",
            "5 * x + 9 * y + -45 * 1\n",
            "1 * x + -5 * y + 8 * 1\n",
            "{x: 9/2, y: 5/2}\n",
            "Episode 42: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "6 * x + -1 * y + 3 * 1\n",
            "7 * x + 5 * y + -3 * 1\n",
            "\n",
            "Final state:\n",
            "6 * x + -1 * y + 3 * 1\n",
            "7 * x + 26 * y + 36 * 1\n",
            "{x: -114/163, y: -195/163}\n",
            "Episode 43: reward: -2.000, steps: 60\n",
            "Initial state:\n",
            "-2 * x + 5 * y + -4 * 1\n",
            "-8 * x + -5 * y + 1 * 1\n",
            "\n",
            "Final state:\n",
            "-2 * x + 5 * y + -64 * 1\n",
            "-8 * x + -5 * y + 1 * 1\n",
            "{x: -63/10, y: 257/25}\n",
            "Episode 44: reward: 2.000, steps: 60\n",
            "Initial state:\n",
            "8 * x + -10 * y + -7 * 1\n",
            "6 * x + -2 * y + 3 * 1\n",
            "\n",
            "Final state:\n",
            "8 * x + -10 * y + -66 * 1\n",
            "6 * x + -2 * y + 4 * 1\n",
            "{x: -43/11, y: -107/11}\n",
            "Episode 45: reward: -1.903, steps: 60\n",
            "Initial state:\n",
            "-3 * x + -9 * y + 1 * 1\n",
            "-7 * x + -5 * y + 0 * 1\n",
            "\n",
            "Final state:\n",
            "-54 * x + -15 * y + 1 * 1\n",
            "-7 * x + -2 * y + 0 * 1\n",
            "{x: 2/3, y: -7/3}\n",
            "Episode 46: reward: 1.903, steps: 60\n",
            "Initial state:\n",
            "-2 * x + 1 * y + -1 * 1\n",
            "3 * x + -4 * y + 2 * 1\n",
            "\n",
            "Final state:\n",
            "-2 * x + 1 * y + -61 * 1\n",
            "3 * x + -4 * y + 2 * 1\n",
            "{x: -242/5, y: -179/5}\n",
            "Episode 47: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "-4 * x + 3 * y + 5 * 1\n",
            "-8 * x + -7 * y + 9 * 1\n",
            "\n",
            "Final state:\n",
            "-4 * x + -35 * y + 5 * 1\n",
            "-8 * x + -6 * y + 30 * 1\n",
            "{x: 255/64, y: -5/16}\n",
            "Episode 48: reward: -1.951, steps: 60\n",
            "Initial state:\n",
            "-4 * x + 7 * y + 5 * 1\n",
            "-5 * x + -2 * y + 0 * 1\n",
            "\n",
            "Final state:\n",
            "-17 * x + -28 * y + 2 * 1\n",
            "-10 * x + 2 * y + 0 * 1\n",
            "{x: 2/157, y: 10/157}\n",
            "Episode 49: reward: 0.000, steps: 60\n",
            "Initial state:\n",
            "3 * x + -7 * y + 0 * 1\n",
            "-5 * x + 2 * y + 4 * 1\n",
            "\n",
            "Final state:\n",
            "3 * x + -37 * y + 0 * 1\n",
            "-5 * x + 2 * y + 34 * 1\n",
            "{x: 1258/179, y: 102/179}\n",
            "Episode 50: reward: -0.049, steps: 60\n",
            "-1.7763568394002505e-17\n"
          ]
        }
      ],
      "source": [
        "fscores = dqn.test(env, nb_episodes=50, visualize=False)\n",
        "print(np.mean(scores.history['episode_reward']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjhO0LyyHspr"
      },
      "source": [
        "# 4. Reloading Agent from Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNS980OXoTma"
      },
      "outputs": [],
      "source": [
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "VqS86QCgHspr",
        "outputId": "c7aa227f-953a-4511-af9e-7dc0f32a9fce"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-221-1b909d1fcc8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dqn_weights.h5f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'dqn' is not defined"
          ]
        }
      ],
      "source": [
        "dqn.save_weights('dqn_weights.h5f', overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttD_RHG-Hspr"
      },
      "outputs": [],
      "source": [
        "del model\n",
        "del dqn\n",
        "del env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "HeMAO8wtHspr",
        "outputId": "f3048eb3-f024-4a8a-942c-b96bec37a189"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-219-03024c025fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CartPole-v0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gym' is not defined"
          ]
        }
      ],
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "actions = env.action_space.n\n",
        "states = env.observation_space.shape[0]\n",
        "model = build_model(states, actions)\n",
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSFOw3HfHspr"
      },
      "outputs": [],
      "source": [
        "dqn.load_weights('dqn_weights.h5f')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVTBbUThHsps",
        "outputId": "a0a34127-5db0-4ce3-c6fb-3b721af4adbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 5 episodes ...\n",
            "WARNING:tensorflow:From /Users/nicholasrenotte/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n"
          ]
        }
      ],
      "source": [
        "_ = dqn.test(env, nb_episodes=5, visualize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcMaX0pZHsps"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "OpenAI-Math.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}